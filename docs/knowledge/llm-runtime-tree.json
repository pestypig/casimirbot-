{
  "version": 1,
  "rootId": "llm-runtime-tree",
  "nodes": [
    {
      "id": "llm-runtime-tree",
      "slug": "llm-runtime-tree",
      "title": "LLM Runtime Tree",
      "excerpt": "Local and remote LLM runtime, tool backends, and tokenizer safeguards.",
      "bodyMD": "This tree maps the LLM runtime surfaces, backend adapters, and guardrails that keep LLM outputs aligned with the physics console.\n\nMinimal artifact: LLM runtime map with backend + guardrails.",
      "tags": [
        "llm",
        "runtime",
        "inference"
      ],
      "children": [
        "llm-runtime-core",
        "llm-runtime-backends",
        "llm-runtime-artifacts",
        "llm-runtime-worker",
        "llm-runtime-rag",
        "llm-runtime-tokenizer",
        "llm-runtime-contracts"
      ],
      "links": [],
      "summary": "Local and remote LLM runtime, tool backends, and tokenizer safeguards.",
      "nodeType": "concept",
      "inputs": [],
      "outputs": [],
      "assumptions": [],
      "validity": {},
      "deterministic": null,
      "tolerance": null,
      "environment": null,
      "dependencies": [],
      "predictability": {
        "status": "partial",
        "missing": [
          "inputs",
          "outputs",
          "assumptions",
          "validity",
          "deterministic",
          "tolerance",
          "environment"
        ]
      },
      "evidence": [
        {
          "type": "doc",
          "path": "docs/knowledge/llm-runtime-tree.json",
          "repo_rev": "a993f4618e92989c20b05232addbc333ded95a29",
          "content_hash": "sha256:0023838af9df893e02f7991c2576e8198233ef1562cb5e5d729819f8f9f61e73"
        }
      ]
    },
    {
      "id": "llm-runtime-core",
      "slug": "llm-runtime-core",
      "title": "Runtime Routes and Services",
      "excerpt": "Small LLM routing and service glue.",
      "bodyMD": "LLM runtime service entry points (server/routes/small-llm.ts, server/services/small-llm.ts).\n\nMinimal artifact: LLM service routing summary.",
      "tags": [
        "llm",
        "routes",
        "backend"
      ],
      "children": [],
      "links": [
        {
          "rel": "parent",
          "to": "llm-runtime-tree"
        }
      ],
      "summary": "Small LLM routing and service glue.",
      "nodeType": "concept",
      "evidence": [
        {
          "type": "code",
          "path": "server/routes/small-llm.ts",
          "repo_rev": "a993f4618e92989c20b05232addbc333ded95a29",
          "content_hash": "sha256:3ee80c1419f92c2ff38d564d3bb516d00c61e0f7375954875ae60c890510cc62"
        },
        {
          "type": "code",
          "path": "server/services/small-llm.ts",
          "repo_rev": "a993f4618e92989c20b05232addbc333ded95a29",
          "content_hash": "sha256:d23e3bf27aebfe925ef981183941a3a5ae8e7e009ff43d17f2cb199188bc213e"
        }
      ],
      "inputs": [],
      "outputs": [],
      "assumptions": [],
      "validity": {},
      "deterministic": null,
      "tolerance": null,
      "environment": null,
      "dependencies": [
        "llm-runtime-tree"
      ],
      "predictability": {
        "status": "partial",
        "missing": [
          "inputs",
          "outputs",
          "assumptions",
          "validity",
          "deterministic",
          "tolerance",
          "environment"
        ]
      }
    },
    {
      "id": "llm-runtime-backends",
      "slug": "llm-runtime-backends",
      "title": "Backend Adapters",
      "excerpt": "HTTP and local LLM backends exposed as tools.",
      "bodyMD": "LLM tool backends (server/skills/llm.http.ts, server/skills/llm.local.ts, server/skills/llm.local.spawn.ts).\n\nMinimal artifact: backend selection map.",
      "tags": [
        "llm",
        "skills",
        "backend"
      ],
      "children": [],
      "links": [
        {
          "rel": "parent",
          "to": "llm-runtime-tree"
        },
        {
          "rel": "see-also",
          "to": "skills-tooling-tree"
        }
      ],
      "summary": "HTTP and local LLM backends exposed as tools.",
      "nodeType": "concept",
      "evidence": [
        {
          "type": "code",
          "path": "server/skills/llm.http.ts",
          "repo_rev": "a993f4618e92989c20b05232addbc333ded95a29",
          "content_hash": "sha256:e594539458a5717ea2302f737c63b21083dc5e866468e3eb1636dfddd015b1ce"
        },
        {
          "type": "code",
          "path": "server/skills/llm.local.ts",
          "repo_rev": "a993f4618e92989c20b05232addbc333ded95a29",
          "content_hash": "sha256:5cab5c3f4a582f662251f6a92035f00d2ade2196affeaf0161bf317a573ba318"
        },
        {
          "type": "code",
          "path": "server/skills/llm.local.spawn.ts",
          "repo_rev": "a993f4618e92989c20b05232addbc333ded95a29",
          "content_hash": "sha256:3d135661974d3adc2f5ea3c9ea6355c9908e938e2b05f8824f4251c24546a944"
        }
      ],
      "inputs": [],
      "outputs": [],
      "assumptions": [],
      "validity": {},
      "deterministic": null,
      "tolerance": null,
      "environment": null,
      "dependencies": [
        "llm-runtime-tree"
      ],
      "predictability": {
        "status": "partial",
        "missing": [
          "inputs",
          "outputs",
          "assumptions",
          "validity",
          "deterministic",
          "tolerance",
          "environment"
        ]
      }
    },
    {
      "id": "llm-runtime-artifacts",
      "slug": "llm-runtime-artifacts",
      "title": "Runtime Artifacts",
      "excerpt": "Runtime artifact hydration and integrity checks.",
      "bodyMD": "Runtime artifact hydration (server/services/llm/runtime-artifacts.ts).\n\nMinimal artifact: artifact hydration checklist.",
      "tags": [
        "llm",
        "artifacts",
        "runtime"
      ],
      "children": [],
      "links": [
        {
          "rel": "parent",
          "to": "llm-runtime-tree"
        }
      ],
      "summary": "Runtime artifact hydration and integrity checks.",
      "nodeType": "concept",
      "evidence": [
        {
          "type": "code",
          "path": "server/services/llm/runtime-artifacts.ts",
          "repo_rev": "a993f4618e92989c20b05232addbc333ded95a29",
          "content_hash": "sha256:17cc2a5ed5bfe1df556beffb1ba0da2cc7caa741f2b8dbe81247f53c2412ea48"
        }
      ],
      "inputs": [],
      "outputs": [],
      "assumptions": [],
      "validity": {},
      "deterministic": null,
      "tolerance": null,
      "environment": null,
      "dependencies": [
        "llm-runtime-tree"
      ],
      "predictability": {
        "status": "partial",
        "missing": [
          "inputs",
          "outputs",
          "assumptions",
          "validity",
          "deterministic",
          "tolerance",
          "environment"
        ]
      }
    },
    {
      "id": "llm-runtime-worker",
      "slug": "llm-runtime-worker",
      "title": "Client LLM Worker",
      "excerpt": "Browser-side local inference and model loading.",
      "bodyMD": "Client LLM worker and generators (client/src/workers/llm-worker.ts, client/src/lib/llm/local-generator.ts, client/src/lib/weights/*).\n\nMinimal artifact: local worker dataflow.",
      "tags": [
        "llm",
        "client",
        "worker"
      ],
      "children": [],
      "links": [
        {
          "rel": "parent",
          "to": "llm-runtime-tree"
        }
      ],
      "summary": "Browser-side local inference and model loading.",
      "nodeType": "concept",
      "evidence": [
        {
          "type": "code",
          "path": "client/src/workers/llm-worker.ts",
          "repo_rev": "a993f4618e92989c20b05232addbc333ded95a29",
          "content_hash": "sha256:bdbdc8b108b72d1af04923fe5c7025713f99dcca0e0ee3f8063ace2fa9b2712b"
        },
        {
          "type": "code",
          "path": "client/src/lib/llm/local-generator.ts",
          "repo_rev": "a993f4618e92989c20b05232addbc333ded95a29",
          "content_hash": "sha256:749939e5140fc383cacb161e5e9445aa8d0721d7660e1906583570c1c3fcf581"
        }
      ],
      "inputs": [],
      "outputs": [],
      "assumptions": [],
      "validity": {},
      "deterministic": null,
      "tolerance": null,
      "environment": null,
      "dependencies": [
        "llm-runtime-tree"
      ],
      "predictability": {
        "status": "partial",
        "missing": [
          "inputs",
          "outputs",
          "assumptions",
          "validity",
          "deterministic",
          "tolerance",
          "environment"
        ]
      }
    },
    {
      "id": "llm-runtime-rag",
      "slug": "llm-runtime-rag",
      "title": "Local RAG Support",
      "excerpt": "Local retrieval utilities for LLM generation.",
      "bodyMD": "Local RAG helpers (client/src/lib/rag/*) and knowledge anchors.\n\nMinimal artifact: local retrieval pipeline summary.",
      "tags": [
        "llm",
        "rag",
        "retrieval"
      ],
      "children": [],
      "links": [
        {
          "rel": "parent",
          "to": "llm-runtime-tree"
        },
        {
          "rel": "see-also",
          "to": "knowledge-ingestion"
        }
      ],
      "summary": "Local retrieval utilities for LLM generation.",
      "nodeType": "concept",
      "inputs": [],
      "outputs": [],
      "assumptions": [],
      "validity": {},
      "deterministic": null,
      "tolerance": null,
      "environment": null,
      "dependencies": [
        "llm-runtime-tree"
      ],
      "predictability": {
        "status": "partial",
        "missing": [
          "inputs",
          "outputs",
          "assumptions",
          "validity",
          "deterministic",
          "tolerance",
          "environment"
        ]
      },
      "evidence": [
        {
          "type": "doc",
          "path": "docs/knowledge/llm-runtime-tree.json",
          "repo_rev": "a993f4618e92989c20b05232addbc333ded95a29",
          "content_hash": "sha256:0023838af9df893e02f7991c2576e8198233ef1562cb5e5d729819f8f9f61e73"
        }
      ]
    },
    {
      "id": "llm-runtime-tokenizer",
      "slug": "llm-runtime-tokenizer",
      "title": "Tokenizer Guardrails",
      "excerpt": "Tokenizer registry, canaries, and verification tools.",
      "bodyMD": "Tokenizer guardrails and verification tooling (docs/tokenizer-guardrails.md, server/config/tokenizer-registry.json, tools/tokenizer-verify.ts, tools/generate-tokenizer-canary.ts, tests/tokenizer-canary.spec.ts, tests/fixtures/tokenizer-canary.json).\n\nMinimal artifact: tokenizer guardrail checklist.",
      "tags": [
        "llm",
        "tokenizer",
        "guardrails"
      ],
      "children": [],
      "links": [
        {
          "rel": "parent",
          "to": "llm-runtime-tree"
        }
      ],
      "summary": "Tokenizer registry, canaries, and verification tools.",
      "nodeType": "concept",
      "evidence": [
        {
          "type": "doc",
          "path": "docs/tokenizer-guardrails.md",
          "repo_rev": "a993f4618e92989c20b05232addbc333ded95a29",
          "content_hash": "sha256:00198877ec11fa63bfefb34b461dc91b1e0172a6145f72f0cbd707fb95d10044"
        },
        {
          "type": "code",
          "path": "server/config/tokenizer-registry.js"
        },
        {
          "type": "code",
          "path": "tools/tokenizer-verify.ts",
          "repo_rev": "a993f4618e92989c20b05232addbc333ded95a29",
          "content_hash": "sha256:f30fe5df06438c0092dd79dfdc471d61dfb16fe29c66a7313593ed6646714771"
        },
        {
          "type": "code",
          "path": "tools/generate-tokenizer-canary.ts",
          "repo_rev": "a993f4618e92989c20b05232addbc333ded95a29",
          "content_hash": "sha256:1677524f9bec96c49293284d7a4216a8000b517e24a10cc288db4f3c07ffb7e7"
        },
        {
          "type": "test",
          "path": "tests/tokenizer-canary.spec.ts",
          "repo_rev": "a993f4618e92989c20b05232addbc333ded95a29",
          "content_hash": "sha256:181b5bea1fa7929aaf4dcf90e4460ed2022409f72cff8e029491fe55c7230747"
        },
        {
          "type": "test",
          "path": "tests/fixtures/tokenizer-canary.js"
        }
      ],
      "inputs": [],
      "outputs": [],
      "assumptions": [],
      "validity": {},
      "deterministic": null,
      "tolerance": null,
      "environment": null,
      "dependencies": [
        "llm-runtime-tree"
      ],
      "predictability": {
        "status": "partial",
        "missing": [
          "inputs",
          "outputs",
          "assumptions",
          "validity",
          "deterministic",
          "tolerance",
          "environment"
        ]
      }
    },
    {
      "id": "llm-runtime-contracts",
      "slug": "llm-runtime-contracts",
      "title": "LLM Contracts",
      "excerpt": "LLM behavior contracts and local setup notes.",
      "bodyMD": "LLM role contracts and setup notes (docs/warp-llm-contracts.md, docs/local-llm-windows.md, docs/warp-console-architecture.md).\n\nMinimal artifact: LLM contract summary.",
      "tags": [
        "llm",
        "contracts",
        "policy"
      ],
      "children": [],
      "links": [
        {
          "rel": "parent",
          "to": "llm-runtime-tree"
        },
        {
          "rel": "see-also",
          "to": "telemetry-console-tree"
        }
      ],
      "summary": "LLM behavior contracts and local setup notes.",
      "nodeType": "concept",
      "evidence": [
        {
          "type": "doc",
          "path": "docs/warp-llm-contracts.md",
          "repo_rev": "a993f4618e92989c20b05232addbc333ded95a29",
          "content_hash": "sha256:a47847b6346a6a6c024af85ddf7d52757fdaf6a324f99576659211ac3fb1c5d0"
        },
        {
          "type": "doc",
          "path": "docs/local-llm-windows.md",
          "repo_rev": "a993f4618e92989c20b05232addbc333ded95a29",
          "content_hash": "sha256:0de98f086883d93bce635aba376c2793144e2f7359a72d8804aee0d620b703de"
        },
        {
          "type": "doc",
          "path": "docs/warp-console-architecture.md",
          "repo_rev": "a993f4618e92989c20b05232addbc333ded95a29",
          "content_hash": "sha256:47b77a13241ba6fcf417d3590697c7211199f8c9f02f6db33557163a25fb1a15"
        }
      ],
      "inputs": [],
      "outputs": [],
      "assumptions": [],
      "validity": {},
      "deterministic": null,
      "tolerance": null,
      "environment": null,
      "dependencies": [
        "llm-runtime-tree"
      ],
      "predictability": {
        "status": "partial",
        "missing": [
          "inputs",
          "outputs",
          "assumptions",
          "validity",
          "deterministic",
          "tolerance",
          "environment"
        ]
      }
    }
  ],
  "schema": {
    "name": "helix-ask-dag-node",
    "version": 1
  }
}
